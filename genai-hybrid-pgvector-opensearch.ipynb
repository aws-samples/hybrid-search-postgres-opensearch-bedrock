{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01cb58e",
   "metadata": {},
   "source": [
    "# Build LLM powered hybrid vector search with Amazon Aurora PostgreSQL, Amazon OpenSearch, Langchain and Bedrock\n",
    "_**Using a pretrained LLM on Bedrock for similarity search on Amazon product reviews using pgvector and OpenSearch**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Downloading Amazon Fine Food Reviews data](#Downloading-Amazon-Fine-Food-Reviews-data)\n",
    "1. [Store the vectors in Aurora PostgreSQL](#Store-the-vectors-in-Aurora-PostgreSQL)\n",
    "1. [Store the vectors in Amazon OpenSearch](#Store-the-vectors-in-Amazon-OpenSearch)\n",
    "1. [Perform hybrid search using vectors stored in Aurora PostgreSQL and Amazon OpenSearch](#Perform-hybrid-search-using-vectors-stored-in-Aurora-PostgreSQL-and-Amazon-OpenSearch)\n",
    "1. [Conclusion](#Conclusion)\n",
    "\n",
    "## Background\n",
    "\n",
    "Vector search is a powerful technique that enables efficient and accurate retrieval of relevant data from large datasets. It represents data as high-dimensional vectors in a vector space, allowing for similarity comparisons based on vector distances. This approach is particularly useful when dealing with complex data structures, such as text, images, or numerical data, where traditional keyword-based search methods may fall short. \n",
    "\n",
    "In the context of AWS, there are several vector database options available for performing vector search. One option is Amazon Aurora for PostgreSQL with the pgvector extension, which provides vector support for structured data stored in relational databases. This extension enables vector operations, such as similarity searches, clustering, and nearest neighbor queries, directly within the PostgreSQL database. \n",
    "\n",
    "Another option is Amazon OpenSearch, a managed service that combines the power of OpenSearch with the scalability and security of AWS. Amazon OpenSearch supports vector search out-of-the-box, making it well-suited for unstructured data, such as text documents, product descriptions, or customer reviews. Hybrid search, which combines both structured and unstructured data sources, is becoming increasingly important as organizations grapple with data that spans multiple formats and sources. \n",
    "By leveraging both structured data from relational databases and unstructured data from search engines or document repositories, organizations can gain a more comprehensive understanding of their data and unlock new insights. \n",
    "\n",
    "In this notebook, we will explore how to perform vector search on structured data using Amazon Aurora for PostgreSQL with the pgvector extension, and on unstructured data using Amazon OpenSearch. We will then combine the results from both sources using Langchain's EnsembleRetriever, which takes a list of retrievers as input, ensembles their results, and re-ranks them based on the Reciprocal Rank Fusion algorithm. The Reciprocal Rank Fusion algorithm is a widely-used technique for combining the results of multiple retrieval systems. It works by assigning weights to each retrieval system based on their performance on a particular query, and then re-ranking the combined results accordingly. This approach helps to leverage the strengths of each retrieval system and provide more accurate and relevant search results. By combining vector search on structured and unstructured data, and leveraging the power of Langchain's EnsembleRetriever, we can unlock the full potential of hybrid search and deliver more comprehensive and accurate search results to end-users..\n",
    "\n",
    "Here are the steps we'll follow to build this hybrid search: After some initial setup, we'll  generate feature vectors for Amazon Fine Food Reviews dataset from *__Kaggle__*. Those feature vectors will be stored both in Amazon Aurora for PostgreSQL and Amazon OpenSearch. Next, we'll explore some sample text queries  byusing 'Anthropic Cluade on Bedrock', and visualize the results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7045906",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install required python libraries for the workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb79cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain pgvector opensearch-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef812ba9-ebbe-464d-84d0-2b5765126f90",
   "metadata": {},
   "source": [
    "Import the required modules and classes from Langchain for document loading, text splitting, embedding generation, vector storage, Bedrock etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6202a5-54bc-4b4a-a0a7-26e32a965145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "import boto3\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.llms.bedrock import Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283ad62",
   "metadata": {},
   "source": [
    "### Downloading Amazon Fine Food Reviews data\n",
    "\n",
    "This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n",
    "\n",
    "**Downloading food reviews from Amazon data**: Data originally from here: https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews \n",
    "\n",
    " **Citation:** <br>\n",
    " http://i.stanford.edu/~julian/pdfs/www13.pdf <br>\n",
    " *J. McAuley and J. Leskovec. From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews. WWW, 2013.* <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the CSV file from the downloaded dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " # We are just using subset of ~300 MB file from Kaggle. Change this to consume full data \n",
    "df = pd.read_csv('data/Reviews_small.csv') \n",
    "df.head()\n",
    "\n",
    "df['reviews'] = df['Summary'] + df['Text']  # We are only interested in Summary and Text columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cd0d4",
   "metadata": {},
   "source": [
    "After reading the CSV file from the downloaded dataset, split the text data into smaller chunks using Langchain's RecursiveCharacterTextSplitter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c409edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load documents from Pandas dataframe for insertion into database\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size = 1000,\n",
    "  chunk_overlap = 20,\n",
    "  length_function = len,\n",
    "  is_separator_regex = False,\n",
    ")\n",
    "\n",
    "# page_content_column is the column name in the dataframe that contains the we'll create embeddings for\n",
    "loader = DataFrameLoader(df, page_content_column = 'reviews')\n",
    "\n",
    "pages = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b73a4b-e275-4139-a11a-e57fefdf9a54",
   "metadata": {},
   "source": [
    "### Store the vectors in Aurora PostgreSQL\n",
    "\n",
    "Retrieve the Amazon Aurora PostgreSQL credentials from AWS Secrets Manager and construct the connection string. Aurora PostgreSQL with the pgvector extension will be used for storing and retrieving structured data vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daf917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "import json \n",
    "\n",
    "region = \"us-east-1\" #Replace it with your region\n",
    "\n",
    "def get_secret(secret_name, region_name):\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString'] \n",
    "    return secret\n",
    "\n",
    "#Replace it with your secret key\n",
    "database_secrets = json.loads(get_secret('demo-secret', region))\n",
    "dbhost = database_secrets['host']\n",
    "dbport = database_secrets['port']\n",
    "dbuser = database_secrets['username']\n",
    "dbpass = database_secrets['password']\n",
    "\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(                                                  \n",
    "    driver = 'psycopg2',\n",
    "    user = dbuser,                                      \n",
    "    password = dbpass,                                  \n",
    "    host = dbhost,                                            \n",
    "    port = dbport,                                          \n",
    "    database = 'postgres' ) #Replace it with your database name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c4908-9dc9-4a89-b7f9-bb6cd7e4673a",
   "metadata": {},
   "source": [
    "Store the document chunks in Amazon Aurora PostgreSQL using Langchain's BedrockEmbeddings, which utilizes the Titan Embeddings model (amazon.titan-embed-text-v1) for generating vector representations of the text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76357427",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"review_collection\" #Replace it with your collection name\n",
    "\n",
    "# Initialize the text embedding model\n",
    "embeddings = BedrockEmbeddings()\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "                                documents=pages,\n",
    "                                embedding=embeddings,\n",
    "                                collection_name=COLLECTION_NAME,\n",
    "                                connection_string=CONNECTION_STRING\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f04a9e-0939-4e24-9e5d-071066e43cf2",
   "metadata": {},
   "source": [
    "Run a sample similarity search query on Amazon Aurora PostgreSQL to ensure that the vector embeddings are properly inserted and can be retrieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dbc0f-61de-4cf2-a6ae-86051ab4b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Query for which we want to find semantically similar documents\n",
    "query = \"Tell me about Vitality canned dog food?\"\n",
    "\n",
    "#Fetch the k=3 most similar documents\n",
    "docs = db.similarity_search(query, k=3)\n",
    "\n",
    "doc = docs[0]\n",
    "# Access the document's content\n",
    "doc_content = doc.page_content\n",
    "\n",
    "print(\"Content snippet:\" + doc_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c060e9-539a-41ea-9c01-4024395299af",
   "metadata": {},
   "source": [
    "### Store the vectors in Amazon OpenSearch\n",
    "\n",
    "Retrieve the Amazon OpenSearch credentials from AWS Secrets Manager. Amazon OpenSearch will be used for storing and retrieving unstructured data vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abbfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_secrets = json.loads(get_secret('demo-secret-opensearch', region)) #Replace it with your secret key\n",
    "osurl = opensearch_secrets['opensearch_endpoint']\n",
    "osuser = opensearch_secrets['opensearch_user']\n",
    "ospass = opensearch_secrets['opensearch_password']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e107d",
   "metadata": {},
   "source": [
    "Create an index in Amazon OpenSearch if one does not already exist. This index will be used to store the vector embeddings of the unstructured data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468de6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': osurl, 'port': 443}],\n",
    "    http_auth=(osuser, ospass),\n",
    "    use_ssl=True,\n",
    "    verify_certs=True\n",
    ")\n",
    "\n",
    "index_name = \"food-review\" #Replace it with your index name\n",
    "indexBody = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"vector_field\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                 \"dimension\": 1536,\n",
    "                \"method\": {\n",
    "                    \"engine\": \"faiss\",\n",
    "                    \"name\": \"hnsw\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    create_response = client.indices.create(index_name, body=indexBody)\n",
    "    print('\\nCreating index:')\n",
    "    print(create_response)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"(Index likely already exists?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2f17d-e70c-4d45-a442-940fd2ea5da5",
   "metadata": {},
   "source": [
    "Store the document chunks in Amazon OpenSearch using Langchain's BedrockEmbeddings, which utilizes the Titan Embeddings model (amazon.titan-embed-text-v1) for generating vector representations of the text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809883d1-c9df-47f4-a68e-fa6014503dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "vector_store = OpenSearchVectorSearch.from_documents(\n",
    "        documents=pages,\n",
    "        embedding=embeddings,\n",
    "        opensearch_url=f\"https://{osurl}\",\n",
    "        http_auth=(osuser, ospass),\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        index_name='food-review' #Replace it with your index name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041cb862-846f-4430-a0fb-8d4d45597640",
   "metadata": {},
   "source": [
    " Run a sample similarity search query on Amazon OpenSearch to ensure that the vector embeddings are properly inserted and can be retrieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719314e-36f9-4eaa-ac76-9bc2a238dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for which we want to find semantically similar documents\n",
    "query = \"Tell me about Vitality canned dog food?\"\n",
    "\n",
    "#Fetch the k=3 most similar documents\n",
    "docs = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "doc = docs[1]\n",
    "# Access the document's content\n",
    "doc_content = doc.page_content\n",
    "\n",
    "print(\"Content snippet:\" + doc_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f719902-fed3-4080-94c8-00613c9c8e72",
   "metadata": {},
   "source": [
    "### Perform hybrid search using vectors stored in Aurora PostgreSQL and Amazon OpenSearch\n",
    "\n",
    "Combine the search results from Amazon OpenSearch (unstructured data) and Amazon Aurora PostgreSQL (structured data) using Langchain's EnsembleRetriever. The EnsembleRetriever takes a list of retrievers as input, ensembles their results, and re-ranks them based on the Reciprocal Rank Fusion algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f4266-1086-4e2b-ab62-caaee89a9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "pgvector_retriever = db.as_retriever(search_kwargs={\"k\":3})\n",
    "opensearch_retriever = vector_store.as_retriever(search_kwargs={\"k\":3})\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[pgvector_retriever, opensearch_retriever], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77fa20-6adf-4480-a981-d7958799c8fd",
   "metadata": {},
   "source": [
    "Make sure that Ensemble Retriever returns the correct results by running a sample query for similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c4d34-4180-4c64-959c-01c63f75e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for which we want to find semantically similar documents\n",
    "query = \"Tell me about Vitality canned dog food?\"\n",
    "\n",
    "#Fetch the k=3 most similar documents\n",
    "docs = ensemble_retriever.get_relevant_documents(query, k=3)\n",
    "\n",
    "doc = docs[0]\n",
    "# Access the document's content\n",
    "doc_content = doc.page_content\n",
    "\n",
    "print(\"Content snippet:\" + doc_content[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e35595-1a99-4b41-a49a-862c368a5801",
   "metadata": {},
   "source": [
    "Perform a query using Anthropic on Bedrock as the language model (llm) and the EnsembleRetriever created in the previous step as the retriever. This step combines the power of Anthropic's language model with the hybrid search capabilities of the EnsembleRetriever, leveraging both structured and unstructured data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43aa12-748f-44a7-a33f-e6dc4302cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Bedrock(\n",
    "                model_id='anthropic.claude-v2', #Replace it with model you want to use\n",
    "                model_kwargs={'max_tokens_to_sample': 4096}\n",
    "            )\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "# Set up the retrieval chain with the language model and database retriever\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "                                        llm=llm,\n",
    "                                        retriever=ensemble_retriever,\n",
    "                                        verbose=True\n",
    "                                    )\n",
    "\n",
    "# Initialize the output callback handler\n",
    "handler = StdOutCallbackHandler()\n",
    "\n",
    "# Run the retrieval chain with a query\n",
    "chain.run(\n",
    "            'how is Vitality canned dog food?',\n",
    "            callbacks=[handler]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd72f8a-2e54-4297-85f9-9cb9bbb9a7b9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By combining vector search on structured and unstructured data sources using Langchain's `EnsembleRetriever`, this notebook demonstrates how to leverage the strengths of different retrieval systems and provide more accurate and relevant search results. \n",
    "\n",
    "This approach is particularly beneficial for organizations dealing with hybrid data environments, where data is spread across multiple formats and sources. By unlocking the potential of hybrid search, organizations can gain a more holistic understanding of their data and uncover valuable insights that might have been missed by relying on a single retrieval system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
